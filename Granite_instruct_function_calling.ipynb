{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "## granite-3.3-2b-instruct en Colab\n",
        "#########################################"
      ],
      "metadata": {
        "id": "m6NDLbAB_Y5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installations\n",
        "\n",
        "import requests, os, re, torch, ast, time\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from transformers.utils import get_json_schema\n",
        "\n",
        "from datetime import datetime, timezone, timedelta\n"
      ],
      "metadata": {
        "id": "gKCst9dHNmdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.3-2b-instruct\")\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE API KEY',\"xxxxxxxxxxxxxxx\")\n",
        "\n",
        "model_path=\"ibm-granite/granite-3.3-2b-instruct\"\n",
        "\n",
        "device=\"cuda\"\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "sfMorcSwBeyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_geolocation() :\n",
        "  return \"Avenida Complutense 30, Madrid, España\"\n",
        "\n",
        "def geocode(address):\n",
        "    if address == 'None':\n",
        "      address = get_geolocation()\n",
        "    geocode_url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={GOOGLE_API_KEY}\"\n",
        "    response = requests.get(geocode_url)\n",
        "    results = response.json()[\"results\"]\n",
        "    if not results:\n",
        "        raise ValueError(f\"No se encontró la dirección: {address}\")\n",
        "    location = results[0][\"geometry\"][\"location\"]\n",
        "    return location[\"lat\"], location[\"lng\"]\n",
        "\n",
        "\n",
        "def get_route_duration(origin: 'None', end: 'None') -> dict:\n",
        "\n",
        "    \"\"\"\n",
        "    Devuelve la duración del trayecto en automóvil desde una dirección de origen a una de destino, y un valor que indica si hay atasco\n",
        "    en el trayecto.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    origin: el punto de comienzo, en formato cadena de caracteres, por ejemplo, \"calle de Torres Quevedo 189, Madrid, España\"\n",
        "\n",
        "    end: destino del trayecto, en formato cadena de caracteres.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    Un diccionario con la respuesta de duración del trayecto y un indicador sobre si hay atasco en la ruta.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Calculando distancia y duración desde {origin} a {end}\")\n",
        "\n",
        "    try:\n",
        "\n",
        "      lat_origen, lon_origen = geocode(origin)\n",
        "      lat_destino, lon_destino = geocode(end)\n",
        "      departure_dt = datetime.now(timezone.utc) + timedelta(minutes=1)\n",
        "      departure_iso_string = departure_dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "      route_url = \"https://routes.googleapis.com/directions/v2:computeRoutes\"\n",
        "      headers = {\n",
        "       \"Content-Type\": \"application/json\",\n",
        "       \"X-Goog-Api-Key\": GOOGLE_API_KEY,\n",
        "        \"X-Goog-FieldMask\": \"*\"\n",
        "      }\n",
        "      # Primero calculamos la duración del trayecto sin tráfico\n",
        "      route_data = {\n",
        "        \"origin\": {\n",
        "            \"location\": {\n",
        "                \"latLng\": {\"latitude\": lat_origen, \"longitude\": lon_origen}\n",
        "            }\n",
        "        },\n",
        "        \"destination\": {\n",
        "          \"location\": {\n",
        "              \"latLng\": {\"latitude\": lat_destino, \"longitude\": lon_destino}\n",
        "          }\n",
        "        },\n",
        "        \"travelMode\": \"DRIVE\",\n",
        "        \"routingPreference\": \"TRAFFIC_UNAWARE\",\n",
        "        \"computeAlternativeRoutes\": False,\n",
        "        \"routeModifiers\": {\n",
        "            \"avoidTolls\": True,\n",
        "            \"avoidHighways\": False,\n",
        "            \"avoidFerries\": True\n",
        "        },\n",
        "        \"languageCode\": \"es-ES\",\n",
        "        \"units\": \"METRIC\"\n",
        "      }\n",
        "      route_response = requests.post(route_url, headers=headers, json=route_data)\n",
        "      route_duration_non_traffic = int(route_response.json()[\"routes\"][0][\"duration\"].rstrip(\"s\"))\n",
        "\n",
        "      # Calculamos el tiempo del trayecto con tráfico\n",
        "\n",
        "      route_data = {\n",
        "        \"origin\": {\n",
        "            \"location\": {\n",
        "                \"latLng\": {\"latitude\": lat_origen, \"longitude\": lon_origen}\n",
        "            }\n",
        "        },\n",
        "        \"destination\": {\n",
        "          \"location\": {\n",
        "              \"latLng\": {\"latitude\": lat_destino, \"longitude\": lon_destino}\n",
        "          }\n",
        "        },\n",
        "        \"travelMode\": \"DRIVE\",\n",
        "        \"routingPreference\": \"TRAFFIC_AWARE\",\n",
        "        \"departureTime\": departure_iso_string,\n",
        "        \"computeAlternativeRoutes\": False,\n",
        "        \"routeModifiers\": {\n",
        "            \"avoidTolls\": True,\n",
        "            \"avoidHighways\": False,\n",
        "            \"avoidFerries\": True\n",
        "        },\n",
        "        \"languageCode\": \"es-ES\",\n",
        "        \"units\": \"METRIC\"\n",
        "      }\n",
        "      route_response = requests.post(route_url, headers=headers, json=route_data)\n",
        "      route_duration_traffic = int(route_response.json()[\"routes\"][0][\"duration\"].rstrip(\"s\"))\n",
        "\n",
        "      print(\"segundos tráfico\", route_duration_traffic)\n",
        "      print(\"segundos non tráfico\", route_duration_non_traffic)\n",
        "      if route_duration_traffic >= route_duration_non_traffic*1.1 :\n",
        "        traffic_jam = 'yes' # añadimos un item más al diccionario\n",
        "      else :\n",
        "        traffic_jam = 'no'\n",
        "\n",
        "      return {\n",
        "\n",
        "            \"duration\": round(route_duration_traffic/60), # damos la duración en minutos\n",
        "\n",
        "            \"traffic_jam\": traffic_jam\n",
        "      }\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(f\"Error al buscar información en Google Maps: {e}\")\n",
        "\n",
        "        return {\n",
        "\n",
        "            \"duration\": \"none\",\n",
        "\n",
        "            \"traffic_jam\": \"none\"\n",
        "        }\n"
      ],
      "metadata": {
        "id": "LEj60d6wXi8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import get_json_schema\n",
        "tools = [get_json_schema(get_route_duration)]\n",
        "tools"
      ],
      "metadata": {
        "id": "DF7wwfDBRhdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_api_request(instructions) -> str:\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map=device,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    model_parameters = {\n",
        "\n",
        "        \"do_sample\": False, # es equivalente a \"decoding_method\": \"greedy\". Me da como salida el token más probable.\n",
        "\n",
        "        \"max_new_tokens\": 2000,\n",
        "\n",
        "        \"repetition_penalty\": 1.05,\n",
        "\n",
        "        \"eos_token_id\" : TOKENIZER.eos_token_id # es equivalente a \"stop_sequences\": [TOKENIZER.eos_token] y sirve para indicarle al modelo\n",
        "                                                # cuándo parar\n",
        "    }\n",
        "\n",
        "    output = model.generate(\n",
        "        **instructions,\n",
        "        **model_parameters,\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    prediction = tokenizer.decode(output[0], skip_special_tokens=False)\n",
        "    print(\"prediction\", prediction)\n",
        "    print(\"***********************************************************************\")\n",
        "    prediction = tokenizer.decode(output[0, instructions[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "x08NuRf8lUqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question= \"¿Cómo está el tráfico para llegar a la Plaza de España en Madrid?\"\n",
        "#question= \"¿Hay atasco para ir a la Plaza de España en Madrid?\"\n",
        "#question= \"¿Cómo de densa está la circulación para ir a la Plaza de España de Madrid?\"\n",
        "query = question+\" Teniendo en cuenta que el origen es \"+ get_geolocation()\n",
        "\n",
        "conversation = [{\"role\": \"system\",\"content\": \"\"\"Eres un asistente con acceso a las siguientes llamadas a función.\n",
        "Tu tarea es producir una secuencia de llamadas a función en respuesta a la petición del usuario.\n",
        "Muestra la respuesta en lenguaje natural, en español.\n",
        "En tu resultado escribe los argumentos de la función tras \"arguments\" y el nombre de la función tras \"function\"\n",
        "\"\"\"},\n",
        "\n",
        "{\"role\": \"user\", \"content\": query},\n",
        "]\n",
        "\n",
        "instructions = TOKENIZER.apply_chat_template(conversation=conversation, tools=tools, tokenize=False, add_generation_prompt=False)\n",
        "instructions"
      ],
      "metadata": {
        "id": "bUTZxB_wcFOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = TOKENIZER.apply_chat_template(conversation=conversation, tools=tools, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True).to(device)\n",
        "instructions"
      ],
      "metadata": {
        "id": "gAEIQmJqjanH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_traffic = make_api_request(instructions)\n",
        "\n",
        "data_traffic\n",
        "\n"
      ],
      "metadata": {
        "id": "cnMeDcqIYMsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_call(llm_response: str):\n",
        "\n",
        "    tool_request = ast.literal_eval(re.search(\"({.+})\", llm_response, re.DOTALL).group(0)) #re.DOTALL detecta todos los caracteres incluidos los saltos de linea\n",
        "    print(tool_request)\n",
        "    tool_name = tool_request[\"name\"]\n",
        "\n",
        "    tool_arguments = tool_request[\"arguments\"]\n",
        "\n",
        "    tool_response = globals()[tool_name](**tool_arguments)\n",
        "\n",
        "    return tool_response\n"
      ],
      "metadata": {
        "id": "Z3W0kLNnYOFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_response_traffic = tool_call(data_traffic)\n",
        "\n",
        "tool_response_traffic\n"
      ],
      "metadata": {
        "id": "nKEtj6SNYT09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2 =  [\n",
        "\n",
        "    {\"role\": \"system\", \"content\":\n",
        "    \"\"\"\n",
        "    Muestra la respuesta de la función externa en lenguaje natural, en español.\n",
        "    \"\"\"},\n",
        "\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"Haz que la respuesta sea muy breve.\n",
        "    Tu respuesta debe ser muy corta, debes decir: \"No hay atasco\" si traffic_jam es 'no'. E incluir también en la respuesta la duración de trayecto\n",
        "     en minutos.\n",
        "    Tu respuesta debe ser muy corta, debes decir: \"Hay atasco\" si traffic_jam es 'yes'. E incluir también en la respuesta la duración de trayecto en minutos.\n",
        "    No incluyas nombres de calles en tu respuesta\n",
        "    No incluyas nombres de ciudades o pueblos en tu respuesta\n",
        "    No incluyas nombres de países en tu respuesta\n",
        "    \"\"\" },\n",
        "\n",
        "    {\"role\": \"tool_response\", \"content\": str(tool_response_traffic) },\n",
        "\n",
        "]\n",
        "\n",
        "instruction_2 = TOKENIZER.apply_chat_template(conversation=conversation2, tokenize=False, add_generation_prompt=False)\n",
        "instruction_2\n"
      ],
      "metadata": {
        "id": "zhMNWRJOYbYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions_2 = TOKENIZER.apply_chat_template(conversation=conversation2, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True).to(device)\n",
        "\n",
        "data_2 = make_api_request(instructions_2)\n",
        "\n",
        "data_2\n"
      ],
      "metadata": {
        "id": "8FNiAAXZkFut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation3 =  [\n",
        "\n",
        "    {\"role\": \"system\", \"content\":\n",
        "    \"\"\"\n",
        "    Muestra la respuesta de la función externa en lenguaje natural, en español.\n",
        "    \"\"\"},\n",
        "\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"Haz que la respuesta sea muy breve.\n",
        "    Tu respuesta debe ser muy corta, debes decir: \"No hay atasco\" si traffic_jam es 'no'.\n",
        "    Tu respuesta debe ser muy corta, debes decir: \"Hay atasco\" si traffic_jam es 'yes'.\n",
        "    Responde en 3 palabras\n",
        "    La respuesta debería ser: \"No hay atasco\" o \"Hay atasco\"\n",
        "    No incluyas nombres de calles en tu respuesta\n",
        "    No incluyas nombres de ciudades o pueblos en tu respuesta\n",
        "    No incluyas nombres de países en tu respuesta\n",
        "    \"\"\" },\n",
        "\n",
        "    {\"role\": \"tool_response\", \"content\": str(tool_response_traffic) },\n",
        "\n",
        "]\n",
        "\n",
        "instruction_3 = TOKENIZER.apply_chat_template(conversation=conversation3, tokenize=False, add_generation_prompt=False)\n",
        "instruction_3\n"
      ],
      "metadata": {
        "id": "TW79_eNtkXbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions_3 = TOKENIZER.apply_chat_template(conversation=conversation3, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True).to(device)\n",
        "data_3 = make_api_request(instructions_3)\n",
        "\n",
        "data_3"
      ],
      "metadata": {
        "id": "kvYXet-RnOaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}